{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e60fe8-6da8-46af-8f59-71c4360ece48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Step 1: Generator function to yield chunks of data from all parquet files in the folder\n",
    "def yield_parquet_chunks(extracted_folder, chunk_size=500000):\n",
    "    i = 0\n",
    "    print(\"Starting yield\")\n",
    "    for root, _, files in os.walk(extracted_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.parquet'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                print(f\"file path is: {file_path}\")\n",
    "                # Read the file in chunks\n",
    "                for df_chunk in pl.read_parquet(file_path, use_pyarrow=True).iter_slices(chunk_size):\n",
    "                    i += 1\n",
    "                    if (i % 500 ==0):\n",
    "                        print(f\"processed {f} lines.\")\n",
    "                    yield df_chunk\n",
    "\n",
    "# Step 2: Separate function for missing values check\n",
    "def check_missing_values(df_chunk, total_missing_values=None):\n",
    "    missing_values_chunk = df_chunk.null_count()\n",
    "    if total_missing_values is None:\n",
    "        total_missing_values = missing_values_chunk\n",
    "    else:\n",
    "        total_missing_values += missing_values_chunk\n",
    "    return total_missing_values\n",
    "\n",
    "# Step 3: Separate function for duplicates check\n",
    "def check_duplicates(df_chunk, total_duplicates=0):\n",
    "    duplicates_chunk = df_chunk.filter(df_chunk.is_duplicated()).height\n",
    "    return total_duplicates + duplicates_chunk\n",
    "\n",
    "# Step 4: Collect density values for distribution plots\n",
    "def collect_density_values(df_chunk, density_values=[]):\n",
    "    density_values.extend(df_chunk['density'].to_list())\n",
    "    return density_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b61d3-17a8-45ff-b517-f006b546abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_folder = '/Users/karim/Downloads/density-2000/date=2000-01-01/'\n",
    "chunk_size = 5000  # Adjust the chunk size based on your memory capacity\n",
    "\n",
    "# Initialize accumulators\n",
    "total_missing_values = None\n",
    "total_duplicates = 0\n",
    "density_values = []\n",
    "\n",
    "# Measure time for processing\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each chunk yielded by the generator\n",
    "for df_chunk in yield_parquet_chunks(extracted_folder, chunk_size):\n",
    "    # Apply different analysis functions on each chunk\n",
    "    total_missing_values = check_missing_values(df_chunk, total_missing_values)\n",
    "    total_duplicates = check_duplicates(df_chunk, total_duplicates)\n",
    "    density_values = collect_density_values(df_chunk, density_values)\n",
    "    \n",
    "    # Clear the current chunk from memory\n",
    "    df_chunk = None\n",
    "    del df_chunk\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076308e-43f9-46be-8839-2588be7b5228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
